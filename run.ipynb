{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备工作",
   "id": "3aa1fc2e616d412c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T10:23:08.406201Z",
     "start_time": "2024-11-28T10:23:05.799642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import ast\n",
    "import os\n",
    "\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# 加载数据函数\n",
    "def load_data(texts_file, ner_tags_file, ix_to_tag_file):\n",
    "    texts = []\n",
    "    ner_tags = []\n",
    "    ix_to_tag = {}\n",
    "\n",
    "    # 加载文本数据\n",
    "    with open(texts_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sentence = line.strip().split()  # 按空格分割单词\n",
    "            texts.append(sentence)\n",
    "\n",
    "    # 加载标签数据\n",
    "    with open(ner_tags_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tags = list(map(int, line.strip().split()))  # 转换为整数列表\n",
    "            ner_tags.append(tags)\n",
    "\n",
    "    # 加载标签到索引的映射\n",
    "    with open(ix_to_tag_file, 'r', encoding='utf-8') as f:\n",
    "        ix_to_tag = ast.literal_eval(f.read().strip())\n",
    "\n",
    "    return texts, ner_tags, ix_to_tag\n",
    "\n",
    "\n",
    "# 处理数据：将文本和标签转换为索引\n",
    "def prepare_data(texts, ner_tags, max_seq_len):\n",
    "    sentence_indices = []\n",
    "    tag_indices = []\n",
    "\n",
    "    for sentence, tags in zip(texts, ner_tags):\n",
    "        sentence_idx = [word_to_ix.get(word, word_to_ix['<UNK>']) for word in sentence]\n",
    "        tag_idx = tags\n",
    "        sentence_indices.append(sentence_idx)\n",
    "        tag_indices.append(tag_idx)\n",
    "\n",
    "    return sentence_indices, tag_indices\n",
    "\n",
    "\n",
    "# 定义BiLSTM-CRF模型\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, dropout_rate=0.5):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, num_layers=2, bidirectional=True, batch_first=True,\n",
    "                            dropout=dropout_rate)\n",
    "        self.hidden2tag = nn.Linear(HIDDEN_DIM * 2, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, sentence, tags):\n",
    "        embeds = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        return -self.crf(emissions, tags)\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        with torch.no_grad():\n",
    "            embeds = self.embedding(sentence)\n",
    "            lstm_out, _ = self.lstm(embeds)\n",
    "            emissions = self.hidden2tag(lstm_out)\n",
    "            return self.crf.decode(emissions)\n",
    "\n",
    "\n",
    "# 自定义Dataset类\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, max_seq_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        tags = self.labels[idx]\n",
    "\n",
    "        # 对句子和标签进行padding或截断\n",
    "        if len(sentence) > self.max_seq_len:\n",
    "            sentence = sentence[:self.max_seq_len]\n",
    "            tags = tags[:self.max_seq_len]\n",
    "        else:\n",
    "            sentence = sentence + [word_to_ix['<UNK>']] * (self.max_seq_len - len(sentence))\n",
    "            tags = tags + [tag_to_ix[0]] * (self.max_seq_len - len(tags))\n",
    "\n",
    "        return torch.tensor(sentence, dtype=torch.long), torch.tensor(tags, dtype=torch.long)\n",
    "\n",
    "\n",
    "# 打印数据集信息\n",
    "def nums_print(li):\n",
    "    total = 0\n",
    "    for label, label_name in [(1, \"人名(PER)\"), (3, \"地点(LOC)\"), (5, \"组织(ORG)\")]:\n",
    "        num = sum([1 for line in li for i in line if i == label])\n",
    "        total += num\n",
    "        print(f\"{label_name}: {num}  ||  \", end=\"\")\n",
    "    print(f\"总数: {total}\")\n",
    "\n",
    "\n",
    "def evaluate_on_val(model, val_sentences, val_labels):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, label in zip(val_sentences, val_labels):\n",
    "            sentence_tensor = torch.tensor(sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            predicted_tags = model.predict(sentence_tensor)\n",
    "\n",
    "            true_labels.extend(label)\n",
    "            predictions.extend(predicted_tags[0])\n",
    "\n",
    "    total = 0\n",
    "    for i in true_labels:\n",
    "        if i != 0:\n",
    "            total += 1\n",
    "    accuracy = sum([1 for true, pred in zip(true_labels, predictions) if pred == true != 0]) / total\n",
    "\n",
    "    # 生成分类报告\n",
    "    report = classification_report(true_labels, predictions, target_names=list(ix_to_tag.values()),\n",
    "                                   labels=list(ix_to_tag.keys()), output_dict=True, zero_division=1)\n",
    "\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    return accuracy, f1\n",
    "\n",
    "\n",
    "# 定义批次的padding函数\n",
    "def pad_batch(batch):\n",
    "    sentences, tags = zip(*batch)\n",
    "    padded_sentences = pad_sequence(sentences, batch_first=True, padding_value=word_to_ix['<UNK>'])\n",
    "    padded_tags = pad_sequence(tags, batch_first=True, padding_value=tag_to_ix[0])\n",
    "    return padded_sentences, padded_tags\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, train_dataloader, val_sentences, val_labels, epochs=1):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    pre = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for sentence_tensor, tag_tensor in train_dataloader:\n",
    "            model.zero_grad()\n",
    "            sentence_tensor, tag_tensor = sentence_tensor.to(device), tag_tensor.to(device)\n",
    "            loss = model(sentence_tensor, tag_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 在验证集上进行评估\n",
    "        accuracy, f1 = evaluate_on_val(model, val_sentences, val_labels)\n",
    "        print(f\" ======== Epoch {epoch + 1}, Loss: {total_loss:.4f}\", end=\"   ============ 在验证集上  \")\n",
    "        print(f\"accuracy, f1 : {accuracy:.4f}, {f1:.4f}\")\n",
    "        if 0.4 * accuracy + 0.6 * f1 >= pre:\n",
    "            torch.save(model.state_dict(), \"model.pth\")\n",
    "            pre = f1\n",
    "            print(\"saved model\")\n",
    "        model.train()  # 切换回训练模式，以便进行下一轮训练\n",
    "\n",
    "# 评估模型\n",
    "def evaluate_model(model, test_sentences, test_labels):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    bio_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, label in zip(test_sentences, test_labels):\n",
    "            sentence_tensor = torch.tensor(sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            predicted_tags = model.predict(sentence_tensor)\n",
    "\n",
    "            true_labels.extend(label)\n",
    "            predictions.extend(predicted_tags[0])\n",
    "\n",
    "            # 将预测结果转换为BIO格式\n",
    "            sentence_bio = [ix_to_tag[tag] for tag in predicted_tags[0]]\n",
    "            bio_predictions.append(sentence_bio)\n",
    "\n",
    "    total = 0\n",
    "    for i in true_labels:\n",
    "        if i != 0:\n",
    "            total += 1\n",
    "    accuracy = sum([1 for true, pred in zip(true_labels, predictions) if pred == true != 0]) / total\n",
    "\n",
    "    # 生成分类报告\n",
    "    report = classification_report(true_labels, predictions, target_names=list(ix_to_tag.values()),\n",
    "                                   labels=list(ix_to_tag.keys()), output_dict=True, zero_division=1)\n",
    "\n",
    "    precision = report[\"macro avg\"][\"precision\"]\n",
    "    recall = report[\"macro avg\"][\"recall\"]\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    print(\"\\n>>>>>>>>>>>>>>  评价模型  <<<<<<<<<<<<<<<\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # 打印前10个句子的预测结果\n",
    "    print(\"\\n>>>>>>>>>>>>>>  打印测试集前10个句子的预测结果  <<<<<<<<<<<<<<<\")\n",
    "    print(\"Predictions in BIO format:\")\n",
    "    for sentence, bio_pred in zip(test_sentences[:10], bio_predictions[:10]):\n",
    "        sentence_words = [ix_to_word.get(idx, \"<UNK>\") for idx in sentence]\n",
    "        print(f\"Sentence: {' '.join(sentence_words)}\")\n",
    "        print(f\"Predictions (BIO): {' '.join(bio_pred)}\\n\")\n",
    "\n",
    "\n",
    "# 预测单个句子\n",
    "def predict_sentence(model, sentence):\n",
    "    model.eval()\n",
    "    sentence_tensor = torch.tensor([word_to_ix.get(word, word_to_ix['<UNK>']) for word in sentence],\n",
    "                                   dtype=torch.long).unsqueeze(0).to(device)\n",
    "    predicted_tags = model.predict(sentence_tensor)\n",
    "\n",
    "    return [(word, ix_to_tag[tag]) for word, tag in zip(sentence, predicted_tags[0])]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "      载入数据文件\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 加载数据\n",
    "texts, ner_tags, ix_to_tag = load_data('texts.txt', 'tags.txt', \"id_to_label_msra_ner.txt\")     #\n",
    "\n",
    "# 创建词汇表和标签映射\n",
    "word_to_ix = {word: i for i, word in enumerate(sorted(set(word for sentence in texts for word in sentence)))}\n",
    "tag_to_ix = {tag: i for i, tag in enumerate(sorted(set(tag for tags in ner_tags for tag in tags)))}\n",
    "word_to_ix['<UNK>'] = len(word_to_ix)  # 添加 <UNK> 标记\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}"
   ],
   "id": "5bea966c05e83cac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 运行入口",
   "id": "e8f2e3eb23ccee95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T10:23:30.647256Z",
     "start_time": "2024-11-28T10:23:15.118202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 超参数\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "BATCH_SIZE = 48\n",
    "MAX_SEQ_LEN = 128\n",
    "DROPOUT_RATE = 0.5\n",
    "EPOCH = 30\n",
    "\n",
    "# 准备数据\n",
    "sentence_indices, label_indices = prepare_data(texts, ner_tags, MAX_SEQ_LEN)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    sentence_indices, label_indices, test_size=0.2, random_state=42)\n",
    "# 划分训练集和验证集\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_sentences, train_labels, test_size=0.1, random_state=42, shuffle=False)  # 10% 作为验证集\n",
    "\n",
    "\n",
    "print(\"Train Data Info\")\n",
    "nums_print(train_labels)\n",
    "print(\"Test Data Info\")\n",
    "nums_print(test_labels)\n",
    "\n",
    "# 创建DataLoader\n",
    "train_dataset = NERDataset(train_sentences, train_labels, MAX_SEQ_LEN)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "\n",
    "# 创建模型并移动到GPU\n",
    "model = BiLSTM_CRF(len(word_to_ix), len(tag_to_ix), dropout_rate=DROPOUT_RATE).to(device)\n",
    "\n",
    "\n",
    "model_file = \"model.pth\"\n",
    "if os.path.exists(model_file):\n",
    "    use_existing_model = input(\n",
    "        f\"Model file found. Do you want to load the existing model from {model_file}? (y/n): \").lower()\n",
    "    if use_existing_model == \"y\":\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        model.eval()\n",
    "        print(\"Model loaded successfully.\")\n",
    "    else:\n",
    "        os.remove(model_file)\n",
    "        print(\"Model deleted\")\n",
    "        # Train the model\n",
    "        train_model(model, train_dataloader, val_sentences, val_labels, epochs=EPOCH)\n",
    "        model.eval()\n",
    "else:\n",
    "    # 训练模型\n",
    "    train_model(model, train_dataloader, val_sentences, val_labels, epochs=EPOCH)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "# 评估模型\n",
    "evaluate_model(model, test_sentences, test_labels)"
   ],
   "id": "f23bb2ca857ad8c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info\n",
      "人名(PER): 2515  ||  地点(LOC): 2921  ||  组织(ORG): 4594  ||  总数: 10030\n",
      "Test Data Info\n",
      "人名(PER): 826  ||  地点(LOC): 905  ||  组织(ORG): 1287  ||  总数: 3018\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Python37\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:328.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>  评价模型  <<<<<<<<<<<<<<<\n",
      "Accuracy: 0.7977\n",
      "Precision: 0.8628510434668298\n",
      "Recall: 0.8232117564727589\n",
      "F1 Score: 0.8421821857005627\n",
      "\n",
      ">>>>>>>>>>>>>>  打印测试集前10个句子的预测结果  <<<<<<<<<<<<<<<\n",
      "Predictions in BIO format:\n",
      "Sentence: 埃 及 针 灸 协 会 会 长 格 格 里 早 年 曾 到 中 国 学 习 针 灸 ， 是 第 一 个 从 事 针 灸 研 究 和 针 灸 疗 法 的 埃 及 人 。\n",
      "Predictions (BIO): B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O\n",
      "\n",
      "Sentence: 本 次 “ 参 谋 部 ” 部 长 、 前 中 国 队 副 总 教 练 林 诗 铨 说 ， 这 些 幕 后 高 参 来 自 中 国 羽 协 和 各 省 市 羽 毛 球 队 的 主 教 练 ， 他 们 的 统 计 常 常 是 中 国 队 颇 有 价 值 的 参 考 信 息 。\n",
      "Predictions (BIO): O O O O O O O O O O O B-ORG I-ORG I-ORG O O O O B-PER O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O O O O O O O O O\n",
      "\n",
      "Sentence: 现 在 电 话 走 进 千 家 万 户 ， 关 注 自 然 就 多 了 。\n",
      "Predictions (BIO): O O O O O O O O O O O O O O O O O O O\n",
      "\n",
      "Sentence: 结 果 丹 麦 队 较 为 顺 利 地 以 ４ ∶ １ 的 总 比 分 战 胜 瑞 典 队 ， 唯 一 令 人 颇 感 意 外 的 是 ： 丹 麦 名 将 拉 尔 森 以 １ ５ ∶ ５ 、 １ ６ ∶ １ ７ 、 ８ ∶ １ ５ 的 比 分 败 在 瑞 典 队 约 翰 森 的 拍 下 。\n",
      "Predictions (BIO): O O B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O O O O O O O O O O O B-ORG I-ORG O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG B-LOC I-LOC I-LOC O O O O\n",
      "\n",
      "Sentence: 按 照 董 炯 的 实 力 和 名 气 来 讲 ， 他 对 目 前 世 界 男 单 排 名 第 十 二 位 约 纳 森 应 是 中 国 队 计 划 内 必 得 的 一 分 。\n",
      "Predictions (BIO): O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O B-ORG I-ORG I-ORG O O O O O O O O O\n",
      "\n",
      "Sentence: 有 关 股 市 专 家 认 为 ， 人 们 对 外 国 人 来 韩 投 资 的 期 望 落 空 ， 故 大 量 抛 售 是 今 天 股 市 暴 跌 的 主 要 原 因 。\n",
      "Predictions (BIO): O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "\n",
      "Sentence: 此 中 虽 无 造 假 钞 者 与 票 贩 子 的 参 与 ， 但 他 们 的 为 常 人 所 知 的 行 径 搅 乱 了 正 常 人 际 关 系 的 逻 辑 。\n",
      "Predictions (BIO): O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "\n",
      "Sentence: 两 天 前 ， 琼 斯 １ ０ ０ 米 跑 出 了 １ ０ 秒 ７ ９ 的 个 人 历 史 上 第 二 个 好 成 绩 ， 这 一 成 绩 与 李 雪 梅 去 年 八 运 会 上 的 夺 冠 成 绩 相 同 。\n",
      "Predictions (BIO): O O O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O\n",
      "\n",
      "Sentence: 本 报 波 恩 ５ 月 ２ ６ 日 电 记 者 江 建 国 报 道 ： 由 瑞 士 著 名 历 史 学 家 让 — 弗 朗 索 瓦 · 贝 尔 热 教 授 领 导 的 国 际 专 家 委 员 会 ， 昨 天 在 瑞 士 苏 黎 世 向 公 众 公 布 了 期 待 已 久 的 关 于 纳 粹 黄 金 交 易 的 报 告 。\n",
      "Predictions (BIO): O O B-LOC I-LOC O O O O O O O O B-PER I-PER I-PER O O O O B-LOC I-LOC O O O O O O O O B-PER I-PER I-PER I-PER I-PER I-PER I-PER I-PER O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O B-LOC I-LOC B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "\n",
      "Sentence: １ ９ ９ ７ 年 １ ２ 月 的 一 天 ， 来 自 河 北 贫 困 山 区 顺 平 县 下 叔 村 的 孤 儿 王 学 强 ， 从 报 纸 上 读 到 了 保 定 玉 兰 香 厨 师 技 术 学 校 招 生 的 广 告 ， 抱 着 闯 一 闯 、 试 一 试 的 想 法 来 到 了 保 定 。\n",
      "Predictions (BIO): O O O O O O O O O O O O O O B-LOC I-LOC O O I-LOC I-LOC B-LOC I-LOC I-LOC B-LOC I-LOC I-LOC O O O B-PER I-PER I-PER O O O O O O O O B-LOC I-LOC B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4a40ade062b23965"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 单句测试入口",
   "id": "53f03209617fa5d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T10:23:39.329424Z",
     "start_time": "2024-11-28T10:23:39.282352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 单句子测试\n",
    "sentence = [\"来\", \"自\", \"河\", \"北\", \"贫\", \"困\", \"山\", \"区\", \"顺\", \"平\", \"县\", \"下\", \"叔\", \"村\", \"的\", \"孤\", \"儿\", \"王\", \"学\", \"强\", \"，\", \"从\", \"报\", \"纸\", \"上\", \"读\", \"到\", \"了\", \"保\", \"定\", \"玉\", \"兰\", \"香\", \"厨\", \"师\", \"技\", \"术\", \"学\", \"校\", \"招\", \"生\", \"的\", \"广\", \"告\", \"，\", \"抱\", \"着\", \"闯\", \"一\", \"闯\", \"、\", \"试\", \"一\", \"试\", \"的\", \"想\", \"法\", \"来\", \"到\", \"了\", \"保\", \"定\", \"。\"]\n",
    "predictions = predict_sentence(model, sentence)\n",
    "print(\"\\nPredictions for the sentence:\")\n",
    "print(predictions)"
   ],
   "id": "a987efbe38dba99c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for the sentence:\n",
      "[('来', 'O'), ('自', 'O'), ('河', 'B-LOC'), ('北', 'I-LOC'), ('贫', 'O'), ('困', 'O'), ('山', 'O'), ('区', 'I-LOC'), ('顺', 'B-LOC'), ('平', 'I-LOC'), ('县', 'I-LOC'), ('下', 'B-LOC'), ('叔', 'I-LOC'), ('村', 'I-LOC'), ('的', 'O'), ('孤', 'O'), ('儿', 'O'), ('王', 'B-PER'), ('学', 'I-PER'), ('强', 'I-PER'), ('，', 'O'), ('从', 'O'), ('报', 'O'), ('纸', 'O'), ('上', 'O'), ('读', 'O'), ('到', 'O'), ('了', 'O'), ('保', 'B-LOC'), ('定', 'I-LOC'), ('玉', 'B-LOC'), ('兰', 'O'), ('香', 'O'), ('厨', 'O'), ('师', 'O'), ('技', 'O'), ('术', 'O'), ('学', 'O'), ('校', 'O'), ('招', 'O'), ('生', 'O'), ('的', 'O'), ('广', 'O'), ('告', 'O'), ('，', 'O'), ('抱', 'O'), ('着', 'O'), ('闯', 'O'), ('一', 'O'), ('闯', 'O'), ('、', 'O'), ('试', 'O'), ('一', 'O'), ('试', 'O'), ('的', 'O'), ('想', 'O'), ('法', 'O'), ('来', 'O'), ('到', 'O'), ('了', 'O'), ('保', 'O'), ('定', 'O'), ('。', 'O')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T10:23:40.280412Z",
     "start_time": "2024-11-28T10:23:40.264787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = [\"你\", \"好\", \"我\", \"是\", \"王\", \"晓\", \"明\", \"北\", \"京\", \"是\", \"中\", \"国\", \"的\", \"首\", \"都\"]\n",
    "predictions = predict_sentence(model, sentence)\n",
    "print(\"\\nPredictions for the sentence:\")\n",
    "print(predictions)"
   ],
   "id": "7fefa0851bfdd091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for the sentence:\n",
      "[('你', 'O'), ('好', 'O'), ('我', 'O'), ('是', 'O'), ('王', 'B-PER'), ('晓', 'I-PER'), ('明', 'I-PER'), ('北', 'B-LOC'), ('京', 'I-LOC'), ('是', 'O'), ('中', 'B-LOC'), ('国', 'I-LOC'), ('的', 'O'), ('首', 'O'), ('都', 'O')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb263481233a2d80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
